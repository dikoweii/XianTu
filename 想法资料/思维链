什么是思维链（cot）
思维链（COT）是让语言模型在输出正文前，通过预先构建的问题进行详细计划或推理，以此提升模型的逻辑能力，从而获得更好的输出。（类似计算时先打草稿，正确率更高）

用途：
-帮助ai理清状况，减少衣服脱了又脱、多人卡下不知道角色是否在场等低级错误
-提升数值计算的能力
-根据剧情切换文风
-通过COT输出内容，判断ai是否理解角色设定
-和好感度等数值联动控制角色行为？（未尝试）

使用经验：
-必须在正文之前先输出COT才有用
-输出完的COT要删除，否则会成为影响下次输出的干扰
-最好是以问题的形式构建COT，而不是复读要求
-过多剧情方面的推理可能导致ai无视user输入
-可以写通用COT放在预设里，也可以类似状态栏为角色定制
-对参数量低的模型（比如本地部署的7B模型）COT用处不大

用起来就像这样： 
图片
历战王咸鱼
LZ
 — 2024/4/7 14:18
自用COT分享
测试场景：
坎佬预设4.4所有版本（其他预设下可能需要根据预设结构调整用词）
sonnet模型（从原理上讲应该所有模型都有效，不过未经测试不好下定论先叠个甲）

思路：在场角色确认→角色行为分析→根据外部条件修改角色行为→输出要求确认→输出
第一版：
Here's what to think about before the description begins:
<thinking>
Please fill in all placeholders exactly according to this template（in English）:
1) current state
a) Player language and behaviour: XYZ
b) Current npc: XYZ
c) Emerging npc: XYZ

2) NPC Analysis
a) NPC should do: XYZ
b) NPC shouldn't do: XYZ
c) Character Hidden Ideas: XYZ
d) How the npc will respond to the player: XYZ

3) NPC behavioural corrections
a) Player's will:XYZ
b) The will of npc: XYZ
c) Current goals or events drive:XYZ
d) Based on the player's wishes, the npc's wishes, and external conditions, the npc reformulates its behaviour and responses:XYZ

4) Story Plan
a) Important writing requirements:XYZ
b) Important external descriptions and settings: XYZ
c) The part that needs fixing:XYZ
After finished thinking, continue the story below in 500 words（in Chinese）:
</thinking>


第二版（简化分析过程，增加user行为重申和文风）：
Here's what to think about before the description begins:
<thinking>
Please fill in all placeholders exactly according to this template（in English）:

1) Current state
a) Current npc: XYZ
b) New npc: XYZ
c) Exiting npc: XYZ
d) Current scene: XYZ

2) NPC's behaviour
a) Current Player Input: XYZ
b) NPC character: XYZ
c) Deviation from original character, correction: XYZ

3) Story Plan
a) Important Writing Requirements: XYZ
b) The tone of this story is Z so choose style Y
After you have finished thinking, continue the following story  (in Chinese):
</thinking>


第二篇文章


靶向提示定义及其构造思路为本人自行总结。由于提示词工程为一门经验学科，本文主观性较强，如有不同意见，欢迎讨论。
靶向提示为一类高度精简后的强效提示，其靶向性体现在两点，利用LLM的底层特性，与分析解决问题的根源。故靶向提示可以定义为，利用LLM底层特性解决问题根源的一类提示词。
以下将通过一个例子阐述靶向提示的提示词优化思路：
.
问题：输出过长，以及容易抢话
 
分析问题根源
     本质上输出过长与容易抢话本质上是一类问题。输出过长的核心问题在于，对话历史以及提示词影响了AI的生成，在到达要求字数时，继续生成的“惯性”大于字数要求停止作用，而此时，单纯的减少要求字数显然无法获得理想效果。
     而容易抢话的原因则更加简单，即AI依据对话历史与预训练，在文中包含{{user}}内容的“惯性”大于禁止{{user}}内容要求的抑制作用，同时，在单次生成长度明显大于对话历史时，这种“惯性”尤为强烈，因为此时{{user}}内容的过久缺乏使得生成{{user}}概率显著提升。

了解LLM相关特性
     首先我们分析AI的输出到什么时候停止，AI的输出停止，依赖stop（停止字符串），Claude在绝大部分未自定义stop时候，都是在\n\nHuman:处进行停止，也就是说，AI作为文本生成器，生成完当前\n\nAssistant:的内容后，开始继续按上下文生成\n\nHuman:后的内容时，将其截断，使得内容仅包含生成一个Assistant前缀下的内容，而不是继续输出Human与Assistant的对话。
     同时，AI倾向于在\n\nAssistant:下生成一个完整的对话，这与作为对话模型的对齐有关，使得AI在生成\n\nHuman:前总是倾向于生成总结性或者具有结尾要素的内容作为铺垫。

结合特性总结问题
     根据以上分析，我们知道了问题的根源在于告诉AI对话应该在何处停止，而AI的特性告诉我们生成将在\n\nHuman:处停止，那么最后问题的核心就变成了告诉AI应该在何时生成\n\nHuman:。更具体的来说，我们需要要求AI在到达要求字数时，生成\n\nHuman:，即使内容不够完整，同时，在需求{{user}}内容时，生成\n\nHuman:。

构造提示
     最后，需要根据预设等内容进行提示词构造，例如在4.4系列预设中，\n\nHuman:与\n\nAssistant:被设定为玩家与游戏主持，那么生成\n\nHuman:也就等于交换回合。那么最后，得到到的提示大致可以概括为：游戏主持在到达要求字数或需要玩家输入{{user}}内容时，交换回合给玩家，即使内容不够完整。
以上便是一个完整的靶向提示构建优化思路。